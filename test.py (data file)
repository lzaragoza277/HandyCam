import cv2
from cvzone.HandTrackingModule import HandDetector
from cvzone.ClassificationModule import Classifier
import numpy as np
import os
from matplotlib import pyplot as plt
import mediapipe as mp
import math
import time


cap = cv2.VideoCapture(0)
detector = HandDetector(maxHands=1)
classifier = Classifier("Model/keras_model.h5", "Model/labels.txt")

offset = 20
imgSize = 300

folder = "Data/C"
counter = 0

labels = ["A (Left)", "A (Right)", "B (Left)", "B (Right)","C (Left)", "C (Right)", "D (Left)", "D (Right)",
          "E (Left)", "E (Right)", "F (Left)", "F (Right)", "G (Left)", "G (Right)", "H (Left)", "H (Right)", "I (Left)", "I (Right)","J (Left)", "J (Right)", "K (Left)", "K (Right)", "L (Left)", "L (Right)", "M (Left)", "M (Right)", "N (Left)", "N (Right)", "O (Left)", "O (Right)", "P (Left)", "P (Right)", "Q (Left)", "Q (Right)", "R (Left)", "R (Right)", "S (Left)", "S (Right)", "T (Left)", "T (Right)", "U (Left)", "U (Right)", "V (Left)", "V (Right)", "W (Left)", "W (Right)", "X (Left)", "X (Right)", "X (Left)", "X (Right)", "Y (Left)", "Y (Right)", "Z (Left)", "Z (Right)"]

while True:
    success, img = cap.read()
    imgOutput = img.copy()
    hands, img = detector.findHands(img)
    if hands:
        hand = hands[0]
        x, y, w, h = hand['bbox']

        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255
        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]

        imgCropShape = imgCrop.shape

        imgWhite[0:imgCropShape[0], 0:imgCropShape[1]] = imgCrop

        aspectRatio = h/w

        if aspectRatio > 1:
            k = imgSize / w
            wCal = math.ceil(k * w)
            imgResize = cv2.resize(imgCrop, (wCal, imgSize))
            imgResizeShape = imgResize.shape
            wGap = math.ceil((imgSize-wCal) / 2)
            imgWhite[:, wGap:wCal + wGap] = imgResize
            prediction, index = classifier.getPrediction(imgWhite, draw=False)
            print(prediction, index)

        else:
            k = imgSize / h
            hCal = math.ceil(k * h)
            imgResize = cv2.resize(imgCrop, (imgSize, hCal))
            imgResizeShape = imgResize.shape
            hGap = math.ceil((imgSize - hCal) / 2)
            imgWhite[hGap:hCal + hGap, :] = imgResize
            prediction, index = classifier.getPrediction(imgWhite, draw=False)

        cv2.rectangle(imgOutput, (x - offset, y - offset - 50),
                      (x - offset + 90, y - offset - 50 + 50), (255, 0, 255), 4, cv2.FILLED)
        cv2.putText(imgOutput, labels[index], (x, y - 26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 255, 255), 2)
        cv2.rectangle(imgOutput, (x - offset, y - offset),
                      (x + w + offset, y + h + offset), (255, 0, 255), 4)


        cv2.imshow("imgCrop", imgCrop)
        cv2.imshow("imgWhite", imgWhite)

    cv2.imshow("Image", imgOutput)
    cv2.waitKey(1)
